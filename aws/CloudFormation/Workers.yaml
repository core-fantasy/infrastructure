AWSTemplateFormatVersion: '2010-09-09'
Description: Stack for Kubernetes general purpose worker nodes.
Parameters:
  EC2KeyPairName:
    Type: String
    Description: EC2 Key pair name
Resources:

  WorkersAutoScaleGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      DesiredCapacity: '4'
      LaunchConfigurationName: !Ref 'WorkersLaunchConfig'
      MaxSize: '5'
      MinSize: '3'
      Tags:
      - Key: Name
        Value: 'CoreFantasy-WorkerGroup-Node'
        PropagateAtLaunch: 'true'
      - Key: !Join ['', ['kubernetes.io/cluster/', !ImportValue EKSClusterName]]
        Value: 'owned'
        PropagateAtLaunch: 'true'
      TargetGroupARNs:
        - !ImportValue 'GatewayHttpTargetGroup-ARN'
      VPCZoneIdentifier:
        - !ImportValue 'PrivateSubnetIdA'
        - !ImportValue 'PrivateSubnetIdB'
  WorkersLaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Metadata:
      AWS::CloudFormation::Init:
        config:
          files:
            /tmp/WorkersBanner.txt:
              # For some unknown reason pulling from S3 gives a 404, even if the file exists.
              content: |
                " "
                " "
                "      __   __        ___  __           __   __   ___"
                "|  | /  \ |__) |__/ |__  |__)    |\ | /  \ |  \ |__"
                "|/\| \__/ |  \ |  \ |___ |  \    | \| \__/ |__/ |___"
                " "
                " "
              mode: '000444'
              owner: root
              group: root
    Properties:
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: 20  # Minimum value
            VolumeType: gp2
            DeleteOnTermination: true
      IamInstanceProfile: !ImportValue NodeInstanceProfile
      ImageId: ami-0a54c984b9f908c81    # See: https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html
      InstanceMonitoring: false
      InstanceType: t2.large
      KeyName: !Ref 'EC2KeyPairName'
      LaunchConfigurationName: WorkersLaunchConfig
      SecurityGroups:
        - !Ref 'WorkersSecurityGroup'
        - !ImportValue 'NodeSecurityGroup'
      UserData:
        Fn::Base64:
          Fn::Sub:
            - |
              #!/bin/bash
              yum update -y
              /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --region ${AWS::Region} --resource WorkersLaunchConfig
              cd /tmp
              cat WorkersBanner.txt > /etc/ssh_banner
              # See https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/
              #     https://aws.amazon.com/blogs/opensource/improvements-eks-worker-node-provisioning/
              /etc/eks/bootstrap.sh ${EKSClusterName} --kubelet-extra-args --node-labels=node-type=worker
              /opt/aws/bin/cfn-signal --exit-code $? \
                     --stack  ${AWS::StackName} \
                     --resource WorkersAutoScaleGroup \
                     --region ${AWS::Region}
            - EKSClusterName:
                Fn::ImportValue:
                  EKSClusterName
  WorkersSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: WorkersSecurityGroup
      GroupDescription: Allows incoming HTTP & SSH traffic
      SecurityGroupIngress:
        # TODO: probably need to include 8877 at some point for gateway admin
        - FromPort: 31000
          IpProtocol: tcp
          ToPort: 443
          SourceSecurityGroupId: !ImportValue "PublicELBSecurityGroup-Id"
        - CidrIp: '0.0.0.0/0'   # TODO: block all access except from Bastion
          FromPort: 22
          IpProtocol: tcp
          ToPort: 22
        - CidrIp: 0.0.0.0/0
          IpProtocol: icmp
          FromPort: '-1'
          ToPort: '-1'
      VpcId: !ImportValue 'VpcId'
